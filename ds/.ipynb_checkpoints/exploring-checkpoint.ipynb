{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sqlite3, hashlib, requests, json, uuid\n",
    "\n",
    "# Collect to and query the DB for all of the peers\n",
    "conn = sqlite3.connect('../test.db')\n",
    "query = \"SELECT * FROM peers;\"\n",
    "\n",
    "df = pd.read_sql_query(query,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique IPs: 114 Total IPs: 1044\n"
     ]
    }
   ],
   "source": [
    "# Total Unique IPs\n",
    "print(f\"Total Unique IPs: {len(df.address.unique())} Total IPs: {len(df.address)}\")\n",
    "\n",
    "# Getting a df of unique IP+torrent combos only\n",
    "## Hash the IP + torrent name concatenated\n",
    "## Insert hash as own column\n",
    "## Select only unique hashes\n",
    "\n",
    "df[\"ip_tor_hash\"] = df[\"address\"] + df[\"torrent_name\"]\n",
    "df[\"ip_tor_hash\"] = df[\"ip_tor_hash\"].apply(lambda x: hashlib.md5(x.encode()).hexdigest())\n",
    "\n",
    "u_df = df.drop_duplicates(subset=['ip_tor_hash']) # Unique df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get IP Address information from ipinfo.io\n",
    "## e00976a117244e\n",
    "## Get the responses into a larger object that we can iterate through after the queries\n",
    "\n",
    "ips = {}\n",
    "\n",
    "for ip in u_df.address:\n",
    "    r = requests.get(f\"https://ipinfo.io/{ip}?token=e00976a117244e\")\n",
    "    data = json.loads(r.text)\n",
    "    ips[ip] = data\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our IPs to a file for now so we do not lose them and waste API calls on duplications\n",
    "with open(f\"ips_{str(uuid.uuid4())}.json\", \"w\") as f:\n",
    "    f.write(json.dumps(ips))\n",
    "print(ips)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a parser for the IP entries that returns a dictionary for the\n",
    "# Calling function to then insert into the df\n",
    "def ip_parser(ip):\n",
    "    \"\"\"\n",
    "    Takes one IP from the ips dictionary that was created.\n",
    "    ip.addr.is.here : {\n",
    "        ip: ip.addr.is.here,\n",
    "        county: etc....\n",
    "    }\n",
    "    \"\"\"\n",
    "    cleaned_ip = {\n",
    "        \"ip\": \"\", \"hostname\": \"\", \"city\": \"\", \n",
    "        \"region\": \"\", \"country\": \"\", \"loc\": \"\",\n",
    "        \"org\": \"\", \"postal\": \"\", \"timezone\": \"\"\n",
    "        }\n",
    "    \n",
    "    for k,v in ip.items():\n",
    "        cleaned_ip[k] = v\n",
    "        \n",
    "    return { cleaned_ip[\"ip\"]: {\n",
    "        \"address\": cleaned_ip[\"ip\"],\n",
    "        \"hostname\": cleaned_ip[\"hostname\"],\n",
    "        \"city\": cleaned_ip[\"city\"],\n",
    "        \"region\": cleaned_ip[\"region\"],\n",
    "        \"country\": cleaned_ip[\"country\"],\n",
    "        \"loc\": cleaned_ip[\"loc\"],\n",
    "        \"org\": cleaned_ip[\"org\"],\n",
    "        \"postal\": cleaned_ip[\"postal\"],\n",
    "        \"timezone\": cleaned_ip[\"timezone\"]\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter default empty strings for missing values for data clarity. Convert into its own dataframe for insertion into main DF\n",
    "clean_ip_list = {}\n",
    "for ip in ips:    \n",
    "    clean_ip_list[ip] = ip_parser(ips[ip])[ip]\n",
    "    \n",
    "ipdf = pd.DataFrame.from_dict(clean_ip_list).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge into a single df with u_df\n",
    "mu_df = pd.merge(u_df, ipdf, on=\"address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mu_df.sample(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    30\n",
       "DE    14\n",
       "RU     9\n",
       "NL     7\n",
       "FR     6\n",
       "GB     6\n",
       "SE     4\n",
       "JP     3\n",
       "CA     3\n",
       "ES     3\n",
       "FI     3\n",
       "UA     2\n",
       "NO     2\n",
       "HU     2\n",
       "AT     2\n",
       "CZ     2\n",
       "AR     2\n",
       "BR     2\n",
       "AU     2\n",
       "CH     2\n",
       "IT     1\n",
       "SK     1\n",
       "CN     1\n",
       "KR     1\n",
       "VN     1\n",
       "IN     1\n",
       "LT     1\n",
       "LV     1\n",
       "AZ     1\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_df.country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "44157fdafb9e422e9ba11f8ff5306b405013a9efc8aa6f7a0e5c37e9d72f10c7"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
